{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sem_meta import SEMMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_ns_key(key):\n",
    "    \"\"\"\n",
    "    Remove XML namespace from a key.\n",
    "    E.g., '{http://ns.adobe.com/xap/1.0/}CreateDate' -> 'CreateDate'\n",
    "    \"\"\"\n",
    "    return key.split('}')[-1] if '}' in key else key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_dict(elem):\n",
    "    \"\"\"\n",
    "    Recursively convert XML element to dict, handling repeated tags as lists.\n",
    "    \"\"\"\n",
    "    children = list(elem)\n",
    "    if not children:\n",
    "        text = elem.text.strip() if elem.text and elem.text.strip() else None\n",
    "        return text\n",
    "\n",
    "    result = {}\n",
    "    for child in children:\n",
    "        child_dict = xml_to_dict(child)\n",
    "        tag = strip_ns_key(child.tag)\n",
    "        if tag in result:\n",
    "            if not isinstance(result[tag], list):\n",
    "                result[tag] = [result[tag]]\n",
    "            result[tag].append(child_dict)\n",
    "        else:\n",
    "            result[tag] = child_dict\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_ns(d):\n",
    "    \"\"\"\n",
    "    Recursively strip namespaces from dict keys.\n",
    "    \"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        return {strip_ns_key(k): strip_ns(v) for k, v in d.items()}\n",
    "    elif isinstance(d, list):\n",
    "        return [strip_ns(i) for i in d]\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_value(value):\n",
    "    \"\"\"\n",
    "    Parse metadata value into JSON-safe structure.\n",
    "    Handles XML, bytes, lists, and simple key=value lines.\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "\n",
    "    # Unpack tuples/lists\n",
    "    if isinstance(value, (tuple, list)):\n",
    "        return [parse_value(v) for v in value]\n",
    "\n",
    "    # Decode bytes\n",
    "    if isinstance(value, bytes):\n",
    "        try:\n",
    "            value = value.decode(\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # Try XML\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            root = ET.fromstring(value)\n",
    "            return {strip_ns_key(root.tag): xml_to_dict(root)}\n",
    "        except ET.ParseError:\n",
    "            pass\n",
    "\n",
    "        # Try key=value pairs\n",
    "        if \"=\" in value:\n",
    "            kv = {}\n",
    "            for line in value.splitlines():\n",
    "                if \"=\" in line:\n",
    "                    key, val = line.split(\"=\", 1)\n",
    "                    kv[key.strip()] = val.strip()\n",
    "            if kv:\n",
    "                return {\"plain\": kv}\n",
    "\n",
    "    # Ensure JSON-safe\n",
    "    try:\n",
    "        json.dumps(value)\n",
    "        return value\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_meta_to_json(meta):\n",
    "    \"\"\"\n",
    "    Convert SEMMeta metadata dict into JSON-safe dict, parsing all values.\n",
    "    \"\"\"\n",
    "    clean_meta = {}\n",
    "    for k, v in meta.items():\n",
    "        try:\n",
    "            parsed_value = parse_value(v)\n",
    "            clean_meta[str(k)] = strip_ns(parsed_value)\n",
    "        except Exception:\n",
    "            clean_meta[str(k)] = None\n",
    "    return clean_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metadata saved to TestData_json4/tile_sand.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 006.json\n",
      "✅ Metadata saved to TestData_json4/CBS_5kVBD_86pA.json\n",
      "✅ Metadata saved to TestData_json4/KLE256_05spolirised (1).json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 007.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 005.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 011.json\n",
      "✅ Metadata saved to TestData_json4/Acquire HAADF.json\n",
      "✅ Metadata saved to TestData_json4/PMal2-2Lw-Ti-law.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 010.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 004.json\n",
      "✅ Metadata saved to TestData_json4/highcurrent_013.json\n",
      "✅ Metadata saved to TestData_json4/Acquire HAADF4.json\n",
      "✅ Metadata saved to TestData_json4/KLE256_05spolirised.json\n",
      "✅ Metadata saved to TestData_json4/masks_021.json\n",
      "✅ Metadata saved to TestData_json4/masks_020.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 001.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 003.json\n",
      "✅ Metadata saved to TestData_json4/bat414bx5k_002.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 002.json\n",
      "✅ Metadata saved to TestData_json4/372HaAg.json\n",
      "✅ Metadata saved to TestData_json4/tile_0.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 002.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 003.json\n",
      "✅ Metadata saved to TestData_json4/tile_1.json\n",
      "✅ Metadata saved to TestData_json4/BSE_image-Verios.json\n",
      "✅ Metadata saved to TestData_json4/bse x200.json\n",
      "✅ Metadata saved to TestData_json4/tile_3.json\n",
      "✅ Metadata saved to TestData_json4/Tile_002-002-000_0.json\n",
      "✅ Metadata saved to TestData_json4/tile_2.json\n",
      "✅ Metadata saved to TestData_json4/4111aPb.json\n",
      "✅ Metadata saved to TestData_json4/tile_6.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 010.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 004.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 005.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 011.json\n",
      "✅ Metadata saved to TestData_json4/tile_7.json\n",
      "✅ Metadata saved to TestData_json4/tile_5.json\n",
      "✅ Metadata saved to TestData_json4/BAT405_001.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 007.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 006.json\n",
      "✅ Metadata saved to TestData_json4/tile_4.json\n",
      "✅ Metadata saved to TestData_json4/image_002.json\n",
      "✅ Metadata saved to TestData_json4/tile_9.json\n",
      "✅ Metadata saved to TestData_json4/tile_12.json\n",
      "✅ Metadata saved to TestData_json4/tile_8.json\n",
      "✅ Metadata saved to TestData_json4/tile_13.json\n",
      "✅ Metadata saved to TestData_json4/D.json\n",
      "✅ Metadata saved to TestData_json4/Frame01x5k Ti APATIITE.json\n",
      "✅ Metadata saved to TestData_json4/tile_11.json\n",
      "✅ Metadata saved to TestData_json4/Site.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 008.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_Mirror_3 - SliceImage - 009.json\n",
      "✅ Metadata saved to TestData_json4/tile_10.json\n",
      "✅ Metadata saved to TestData_json4/implant ti00.json\n",
      "✅ Metadata saved to TestData_json4/C.json\n",
      "✅ Metadata saved to TestData_json4/image_004.json\n",
      "✅ Metadata saved to TestData_json4/3723aAg.json\n",
      "✅ Metadata saved to TestData_json4/Image15x2.json\n",
      "✅ Metadata saved to TestData_json4/A.json\n",
      "✅ Metadata saved to TestData_json4/4122aCu.json\n",
      "✅ Metadata saved to TestData_json4/Implant 1.json\n",
      "✅ Metadata saved to TestData_json4/KLE256_04 crosspolirised.json\n",
      "✅ Metadata saved to TestData_json4/EPMA_map-Mn.json\n",
      "✅ Metadata saved to TestData_json4/TLD_5kVBD_86pA_SI_001.json\n",
      "✅ Metadata saved to TestData_json4/Acquire BF.json\n",
      "✅ Metadata saved to TestData_json4/RP179905x1200_005.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 009.json\n",
      "✅ Metadata saved to TestData_json4/Slice.json\n",
      "✅ Metadata saved to TestData_json4/SEM Multi-Detector Image_TLD_1 - SliceImage - 008.json\n",
      "✅ Metadata saved to TestData_json4/PP-541-29-Fram-Verios.json\n",
      "✅ Metadata saved to TestData_json4/lowcurrent_014.json\n",
      "✅ Metadata saved to TestData_json4/Tile_006-006-000_0.json\n",
      "\n",
      "===== Summary =====\n",
      "✅ Succeeded: 73\n",
      "❌ Failed: 0\n"
     ]
    }
   ],
   "source": [
    "# ===== MAIN LOOP =====\n",
    "input_folder = Path(\"TestData\")\n",
    "output_folder = Path(\"TestData_json4\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "success_count = 0\n",
    "failures = []\n",
    "\n",
    "for tif_path in input_folder.glob(\"*.tif\"):\n",
    "    try:\n",
    "        with Image.open(tif_path) as im:\n",
    "            meta, tags = SEMMeta.ImageMetadata(im)\n",
    "            json_meta = convert_meta_to_json(meta)\n",
    "\n",
    "            json_path = output_folder / (tif_path.stem + \".json\")\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(json_meta, f, indent=2)\n",
    "\n",
    "            print(f\"✅ Metadata saved to {json_path}\")\n",
    "            success_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to process {tif_path.name}: {e}\")\n",
    "        failures.append(tif_path.name)\n",
    "\n",
    "# ===== SUMMARY =====\n",
    "print(\"\\n===== Summary =====\")\n",
    "print(f\"✅ Succeeded: {success_count}\")\n",
    "print(f\"❌ Failed: {len(failures)}\")\n",
    "if failures:\n",
    "    print(\"Failed images:\", \", \".join(failures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
